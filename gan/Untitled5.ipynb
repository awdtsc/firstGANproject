{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae51b10-37df-475b-807a-890ce794bb8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 148\u001b[0m\n\u001b[0;32m    145\u001b[0m save_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# モデルの構築と訓練\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m generator \u001b[38;5;241m=\u001b[39m MyLayer(latent_dim)(Input(shape\u001b[38;5;241m=\u001b[39m(latent_dim,)))\n\u001b[0;32m    149\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m build_discriminator(img_shape)\n\u001b[0;32m    151\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m, in \u001b[0;36mMyLayer.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape):\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_model()\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28msuper\u001b[39m(MyLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbuild(input_shape)\n",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m, in \u001b[0;36mMyLayer.build_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     28\u001b[0m     noise \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim,))\n\u001b[1;32m---> 29\u001b[0m     img \u001b[38;5;241m=\u001b[39m model(noise)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Model(noise, img)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, latent_dim, **kwargs):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.model = self.build_model()\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.build_generator()(inputs)\n",
    "\n",
    "    def build_model(self):\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 16 * 16, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((16, 16, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        return model\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        img = Image.open(os.path.join(dataset_path, filename))\n",
    "        img = img.resize((64, 64))\n",
    "        img = tf.cast(img, tf.float32) / 127.5 - 1.0\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "# データセットのパスを指定\n",
    "dataset_path = r\"C:\\Users\\user\\Downloads\\sample-cards-data\\images\\images\"\n",
    "X_train = load_data(dataset_path)\n",
    "\n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# GANの構築\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    fake_img = generator(gan_input)\n",
    "    gan_output = discriminator(fake_img)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return gan\n",
    "\n",
    "# 訓練用関数\n",
    "def train_gan(generator, discriminator, gan, X_train, epochs, batch_size=32, save_interval=10):\n",
    "    valid = np.ones((batch_size, 1), dtype=tf.float32)\n",
    "    fake = np.zeros((batch_size, 1), dtype=tf.float32)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(tf.convert_to_tensor(imgs), valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(tf.convert_to_tensor(gen_imgs), fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        g_loss = gan.train_on_batch(noise, valid)\n",
    "\n",
    "        # 進捗の表示\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
    "\n",
    "        # 一定間隔で生成画像を保存\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator, epoch)\n",
    "\n",
    "# 生成した画像を保存する関数\n",
    "def save_imgs(generator, epoch, r=5, c=5):\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # 生成した画像を0から1の範囲に変換\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# パラメータ設定\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "save_interval = 50\n",
    "\n",
    "# モデルの構築と訓練\n",
    "generator = MyLayer(latent_dim)(Input(shape=(latent_dim,)))\n",
    "discriminator = build_discriminator(img_shape)\n",
    "\n",
    "discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "generator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "train_gan(generator, discriminator, gan, X_train, epochs=epochs, batch_size=batch_size, save_interval=save_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e793c4a9-ff42-474f-9020-036519f7cebc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KerasTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 156\u001b[0m\n\u001b[0;32m    153\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m build_discriminator(img_shape)\n\u001b[0;32m    155\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 156\u001b[0m gan \u001b[38;5;241m=\u001b[39m build_gan(generator, discriminator)\n\u001b[0;32m    157\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    159\u001b[0m train_gan(generator, discriminator, gan, X_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, save_interval\u001b[38;5;241m=\u001b[39msave_interval)\n",
      "Cell \u001b[1;32mIn[16], line 98\u001b[0m, in \u001b[0;36mbuild_gan\u001b[1;34m(generator, discriminator)\u001b[0m\n\u001b[0;32m     96\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     97\u001b[0m gan_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(latent_dim,))\n\u001b[1;32m---> 98\u001b[0m fake_img \u001b[38;5;241m=\u001b[39m generator(gan_input)\n\u001b[0;32m     99\u001b[0m gan_output \u001b[38;5;241m=\u001b[39m discriminator(fake_img)\n\u001b[0;32m    100\u001b[0m gan \u001b[38;5;241m=\u001b[39m Model(gan_input, gan_output)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'KerasTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# データの読み込み\n",
    "def load_data(dataset_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        img = Image.open(os.path.join(dataset_path, filename))\n",
    "        img = img.resize((64, 64))\n",
    "        img = tf.cast(img, tf.float32) / 127.5 - 1.0\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "# データセットのパスを指定\n",
    "dataset_path = r\"C:\\Users\\user\\Downloads\\sample-cards-data\\images\\images\"\n",
    "X_train = load_data(dataset_path)\n",
    "\n",
    "# GANのパラメータ設定\n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, latent_dim, **kwargs):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.model = self.build_model()\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        img = self.model(inputs)\n",
    "        return img\n",
    "\n",
    "    def build_model(self):\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        x = Dense(128 * 16 * 16, activation=\"relu\")(noise)\n",
    "        x = Reshape((16, 16, 128))(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(3, kernel_size=3, padding=\"same\")(x)\n",
    "        outputs = Activation(\"tanh\")(x)\n",
    "        return Model(noise, outputs)\n",
    "\n",
    "def build_generator(latent_dim, img_shape):\n",
    "    inputs = Input(shape=(latent_dim,))\n",
    "    x = MyLayer(latent_dim)(inputs)\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "# 識別器の構築\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# GANの構築\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    fake_img = generator(gan_input)\n",
    "    gan_output = discriminator(fake_img)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return gan\n",
    "\n",
    "# 訓練用関数\n",
    "def train_gan(generator, discriminator, gan, X_train, epochs, batch_size=32, save_interval=10):\n",
    "    valid = np.ones((batch_size, 1), dtype=tf.float32)\n",
    "    fake = np.zeros((batch_size, 1), dtype=tf.float32)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(tf.convert_to_tensor(imgs), valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(tf.convert_to_tensor(gen_imgs), fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        g_loss = gan.train_on_batch(noise, valid)\n",
    "\n",
    "        # 進捗の表示\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
    "\n",
    "        # 一定間隔で生成画像を保存\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator, epoch)\n",
    "\n",
    "# 生成した画像を保存する関数\n",
    "def save_imgs(generator, epoch, r=5, c=5):\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # 生成した画像を0から1の範囲に変換\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# パラメータ設定\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "save_interval = 50\n",
    "\n",
    "# モデルの構築と訓練\n",
    "discriminator = build_discriminator(img_shape)\n",
    "\n",
    "discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "train_gan(generator, discriminator, gan, X_train, epochs=epochs, batch_size=batch_size, save_interval=save_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f35480c-0138-4a4c-8e32-5ae03d06af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_87\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(32, 64, 64, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 165\u001b[0m\n\u001b[0;32m    162\u001b[0m gan \u001b[38;5;241m=\u001b[39m build_gan(generator, discriminator)\n\u001b[0;32m    163\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m train_gan(generator, discriminator, gan, X_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, save_interval\u001b[38;5;241m=\u001b[39msave_interval)\n",
      "Cell \u001b[1;32mIn[23], line 120\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, gan, X_train, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m    117\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (batch_size, latent_dim))\n\u001b[0;32m    118\u001b[0m gen_imgs \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[1;32m--> 120\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(imgs, valid)\n\u001b[0;32m    121\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(gen_imgs, fake)\n\u001b[0;32m    122\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39madd(d_loss_real, d_loss_fake)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:540\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 540\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(data())\n\u001b[0;32m    541\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:117\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 117\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    118\u001b[0m     one_step_on_data, args\u001b[38;5;241m=\u001b[39m(data,)\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    120\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    121\u001b[0m     outputs,\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    123\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    124\u001b[0m )\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:104\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:51\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_has_training_arg:\n\u001b[1;32m---> 51\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_87\" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(32, 64, 64, 4)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, latent_dim, **kwargs):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.generator = self.build_generator()\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        img = self.generator(inputs)\n",
    "        return img\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        x = Dense(128 * 16 * 16, activation=\"relu\")(noise)\n",
    "        x = Reshape((16, 16, 128))(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(3, kernel_size=3, padding=\"same\")(x)\n",
    "        outputs = Activation(\"tanh\")(x)\n",
    "        return Model(noise, outputs)\n",
    "        \n",
    "# データの読み込み\n",
    "def load_data(dataset_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        img = Image.open(os.path.join(dataset_path, filename))\n",
    "        img = img.resize((64, 64))\n",
    "        img = tf.cast(img, tf.float32) / 127.5 - 1.0\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "# データセットのパスを指定\n",
    "dataset_path = r\"C:\\Users\\user\\Downloads\\sample-cards-data\\images\\images\"\n",
    "X_train = load_data(dataset_path)\n",
    "\n",
    "# GANのパラメータ設定\n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "\n",
    "def build_generator(latent_dim, img_shape):\n",
    "    inputs = Input(shape=(latent_dim,))\n",
    "    x = MyLayer(latent_dim)(inputs)\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "# 識別器の構築\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "# GANの構築\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    fake_img = generator(gan_input)\n",
    "    gan_output = discriminator(fake_img)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return gan\n",
    "\n",
    "# 訓練用関数\n",
    "def train_gan(generator, discriminator, gan, X_train, epochs, batch_size=32, save_interval=10):\n",
    "    valid = np.ones((batch_size, 1), dtype=np.float32)\n",
    "    fake = np.zeros((batch_size, 1), dtype=np.float32)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        g_loss = gan.train_on_batch(noise, valid)\n",
    "\n",
    "        # 進捗の表示\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
    "\n",
    "        # 一定間隔で生成画像を保存\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator, epoch)\n",
    "\n",
    "# 生成した画像を保存する関数\n",
    "def save_imgs(generator, epoch, r=5, c=5):\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # 生成した画像を0から1の範囲に変換\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# パラメータ設定\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "save_interval = 50\n",
    "\n",
    "# モデルの構築と訓練\n",
    "generator = build_generator(latent_dim, img_shape)\n",
    "discriminator = build_discriminator(img_shape)\n",
    "\n",
    "discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "generator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "train_gan(generator, discriminator, gan, X_train, epochs=epochs, batch_size=batch_size, save_interval=save_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3de649-99f7-4ef3-b733-1d16131350fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:71: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.7263780832290649] [G loss: [array(0.7145185, dtype=float32), array(0.7145185, dtype=float32), array(0.7145185, dtype=float32), array(0.515625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x0000027196CEB420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000271C1626520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1 [D loss: 0.7195343375205994] [G loss: [array(0.7153421, dtype=float32), array(0.7153421, dtype=float32), array(0.7153421, dtype=float32), array(0.515625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "2 [D loss: 0.7170929312705994] [G loss: [array(0.7146282, dtype=float32), array(0.7146282, dtype=float32), array(0.7146282, dtype=float32), array(0.515625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "3 [D loss: 0.7140219807624817] [G loss: [array(0.7123029, dtype=float32), array(0.7123029, dtype=float32), array(0.7123029, dtype=float32), array(0.52734375, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "4 [D loss: 0.712951123714447] [G loss: [array(0.71164405, dtype=float32), array(0.71164405, dtype=float32), array(0.71164405, dtype=float32), array(0.521875, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "5 [D loss: 0.7129654884338379] [G loss: [array(0.71186566, dtype=float32), array(0.71186566, dtype=float32), array(0.71186566, dtype=float32), array(0.5182292, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "6 [D loss: 0.711606502532959] [G loss: [array(0.7107048, dtype=float32), array(0.7107048, dtype=float32), array(0.7107048, dtype=float32), array(0.52008927, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "7 [D loss: 0.7116000652313232] [G loss: [array(0.71073407, dtype=float32), array(0.71073407, dtype=float32), array(0.71073407, dtype=float32), array(0.5253906, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "8 [D loss: 0.7116001844406128] [G loss: [array(0.71086997, dtype=float32), array(0.71086997, dtype=float32), array(0.71086997, dtype=float32), array(0.5190972, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "9 [D loss: 0.7113773226737976] [G loss: [array(0.71070224, dtype=float32), array(0.71070224, dtype=float32), array(0.71070224, dtype=float32), array(0.5140625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "10 [D loss: 0.710797131061554] [G loss: [array(0.71022534, dtype=float32), array(0.71022534, dtype=float32), array(0.71022534, dtype=float32), array(0.5099432, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "11 [D loss: 0.7108031511306763] [G loss: [array(0.71031445, dtype=float32), array(0.71031445, dtype=float32), array(0.71031445, dtype=float32), array(0.50651044, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "12 [D loss: 0.7107360363006592] [G loss: [array(0.71031255, dtype=float32), array(0.71031255, dtype=float32), array(0.71031255, dtype=float32), array(0.49639422, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "13 [D loss: 0.7110460996627808] [G loss: [array(0.7106786, dtype=float32), array(0.7106786, dtype=float32), array(0.7106786, dtype=float32), array(0.48549107, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "14 [D loss: 0.7108949422836304] [G loss: [array(0.71061796, dtype=float32), array(0.71061796, dtype=float32), array(0.71061796, dtype=float32), array(0.471875, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
      "15 [D loss: 0.711134672164917] [G loss: [array(0.710991, dtype=float32), array(0.710991, dtype=float32), array(0.710991, dtype=float32), array(0.45507812, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "16 [D loss: 0.7114588022232056] [G loss: [array(0.71130055, dtype=float32), array(0.71130055, dtype=float32), array(0.71130055, dtype=float32), array(0.4384191, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "17 [D loss: 0.7116665244102478] [G loss: [array(0.711594, dtype=float32), array(0.711594, dtype=float32), array(0.711594, dtype=float32), array(0.42447916, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "18 [D loss: 0.712087869644165] [G loss: [array(0.7120373, dtype=float32), array(0.7120373, dtype=float32), array(0.7120373, dtype=float32), array(0.41036186, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "19 [D loss: 0.7126525640487671] [G loss: [array(0.7127192, dtype=float32), array(0.7127192, dtype=float32), array(0.7127192, dtype=float32), array(0.39609376, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "20 [D loss: 0.7131834030151367] [G loss: [array(0.713305, dtype=float32), array(0.713305, dtype=float32), array(0.713305, dtype=float32), array(0.37872022, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
      "21 [D loss: 0.7141760587692261] [G loss: [array(0.71430945, dtype=float32), array(0.71430945, dtype=float32), array(0.71430945, dtype=float32), array(0.3615057, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "22 [D loss: 0.7150497436523438] [G loss: [array(0.7152666, dtype=float32), array(0.7152666, dtype=float32), array(0.7152666, dtype=float32), array(0.34714675, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "23 [D loss: 0.7158286571502686] [G loss: [array(0.71604246, dtype=float32), array(0.71604246, dtype=float32), array(0.71604246, dtype=float32), array(0.3372396, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "24 [D loss: 0.7166622877120972] [G loss: [array(0.7169026, dtype=float32), array(0.7169026, dtype=float32), array(0.7169026, dtype=float32), array(0.32625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
      "25 [D loss: 0.7176098227500916] [G loss: [array(0.7180249, dtype=float32), array(0.7180249, dtype=float32), array(0.7180249, dtype=float32), array(0.31550482, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "26 [D loss: 0.7185379266738892] [G loss: [array(0.7188888, dtype=float32), array(0.7188888, dtype=float32), array(0.7188888, dtype=float32), array(0.30671296, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "27 [D loss: 0.719444990158081] [G loss: [array(0.7198432, dtype=float32), array(0.7198432, dtype=float32), array(0.7198432, dtype=float32), array(0.29854912, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "28 [D loss: 0.7204323410987854] [G loss: [array(0.7208194, dtype=float32), array(0.7208194, dtype=float32), array(0.7208194, dtype=float32), array(0.28987068, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "29 [D loss: 0.7215061783790588] [G loss: [array(0.72194296, dtype=float32), array(0.72194296, dtype=float32), array(0.72194296, dtype=float32), array(0.28125, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "30 [D loss: 0.7226108312606812] [G loss: [array(0.7231488, dtype=float32), array(0.7231488, dtype=float32), array(0.7231488, dtype=float32), array(0.27419356, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "31 [D loss: 0.7238175868988037] [G loss: [array(0.7243363, dtype=float32), array(0.7243363, dtype=float32), array(0.7243363, dtype=float32), array(0.26708984, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "32 [D loss: 0.7247065305709839] [G loss: [array(0.72513, dtype=float32), array(0.72513, dtype=float32), array(0.72513, dtype=float32), array(0.2623106, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step\n",
      "33 [D loss: 0.7259268164634705] [G loss: [array(0.7265722, dtype=float32), array(0.7265722, dtype=float32), array(0.7265722, dtype=float32), array(0.25505516, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "34 [D loss: 0.7270121574401855] [G loss: [array(0.7275244, dtype=float32), array(0.7275244, dtype=float32), array(0.7275244, dtype=float32), array(0.24955358, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "35 [D loss: 0.728238582611084] [G loss: [array(0.7288245, dtype=float32), array(0.7288245, dtype=float32), array(0.7288245, dtype=float32), array(0.2439236, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "36 [D loss: 0.7294538021087646] [G loss: [array(0.7300936, dtype=float32), array(0.7300936, dtype=float32), array(0.7300936, dtype=float32), array(0.23902027, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
      "37 [D loss: 0.7306985855102539] [G loss: [array(0.7312956, dtype=float32), array(0.7312956, dtype=float32), array(0.7312956, dtype=float32), array(0.23478618, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "38 [D loss: 0.7319947481155396] [G loss: [array(0.7326258, dtype=float32), array(0.7326258, dtype=float32), array(0.7326258, dtype=float32), array(0.22996795, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "39 [D loss: 0.7333173155784607] [G loss: [array(0.7339462, dtype=float32), array(0.7339462, dtype=float32), array(0.7339462, dtype=float32), array(0.22421876, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "40 [D loss: 0.7345592975616455] [G loss: [array(0.7351859, dtype=float32), array(0.7351859, dtype=float32), array(0.7351859, dtype=float32), array(0.21989329, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
      "41 [D loss: 0.7357026934623718] [G loss: [array(0.73629177, dtype=float32), array(0.73629177, dtype=float32), array(0.73629177, dtype=float32), array(0.21651785, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "42 [D loss: 0.7368867993354797] [G loss: [array(0.73754525, dtype=float32), array(0.73754525, dtype=float32), array(0.73754525, dtype=float32), array(0.21257268, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "43 [D loss: 0.7381988763809204] [G loss: [array(0.7388745, dtype=float32), array(0.7388745, dtype=float32), array(0.7388745, dtype=float32), array(0.20987216, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
      "44 [D loss: 0.7393101453781128] [G loss: [array(0.7398813, dtype=float32), array(0.7398813, dtype=float32), array(0.7398813, dtype=float32), array(0.20625, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "45 [D loss: 0.7405763864517212] [G loss: [array(0.7412613, dtype=float32), array(0.7412613, dtype=float32), array(0.7412613, dtype=float32), array(0.20244566, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
      "46 [D loss: 0.7419235706329346] [G loss: [array(0.7426098, dtype=float32), array(0.7426098, dtype=float32), array(0.7426098, dtype=float32), array(0.19880319, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "47 [D loss: 0.7431507706642151] [G loss: [array(0.7437698, dtype=float32), array(0.7437698, dtype=float32), array(0.7437698, dtype=float32), array(0.19563802, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "48 [D loss: 0.7443081736564636] [G loss: [array(0.7449605, dtype=float32), array(0.7449605, dtype=float32), array(0.7449605, dtype=float32), array(0.19260204, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "49 [D loss: 0.7455573081970215] [G loss: [array(0.74617964, dtype=float32), array(0.74617964, dtype=float32), array(0.74617964, dtype=float32), array(0.189375, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "50 [D loss: 0.7465893030166626] [G loss: [array(0.747233, dtype=float32), array(0.747233, dtype=float32), array(0.747233, dtype=float32), array(0.1875, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "51 [D loss: 0.7477388381958008] [G loss: [array(0.7484589, dtype=float32), array(0.7484589, dtype=float32), array(0.7484589, dtype=float32), array(0.18599759, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "52 [D loss: 0.7491652965545654] [G loss: [array(0.74998206, dtype=float32), array(0.74998206, dtype=float32), array(0.74998206, dtype=float32), array(0.18337265, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "53 [D loss: 0.7504242658615112] [G loss: [array(0.75106955, dtype=float32), array(0.75106955, dtype=float32), array(0.75106955, dtype=float32), array(0.18113425, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "54 [D loss: 0.7515501976013184] [G loss: [array(0.75223714, dtype=float32), array(0.75223714, dtype=float32), array(0.75223714, dtype=float32), array(0.17897727, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "55 [D loss: 0.7528833150863647] [G loss: [array(0.7536772, dtype=float32), array(0.7536772, dtype=float32), array(0.7536772, dtype=float32), array(0.17717634, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "56 [D loss: 0.7543595433235168] [G loss: [array(0.7551102, dtype=float32), array(0.7551102, dtype=float32), array(0.7551102, dtype=float32), array(0.17406799, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "57 [D loss: 0.7557201385498047] [G loss: [array(0.75646245, dtype=float32), array(0.75646245, dtype=float32), array(0.75646245, dtype=float32), array(0.171875, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "58 [D loss: 0.7570267915725708] [G loss: [array(0.75780195, dtype=float32), array(0.75780195, dtype=float32), array(0.75780195, dtype=float32), array(0.16949153, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "59 [D loss: 0.7582998275756836] [G loss: [array(0.759065, dtype=float32), array(0.759065, dtype=float32), array(0.759065, dtype=float32), array(0.16848959, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "60 [D loss: 0.7596156597137451] [G loss: [array(0.76039577, dtype=float32), array(0.76039577, dtype=float32), array(0.76039577, dtype=float32), array(0.1664959, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "61 [D loss: 0.760956346988678] [G loss: [array(0.7617194, dtype=float32), array(0.7617194, dtype=float32), array(0.7617194, dtype=float32), array(0.16532259, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "62 [D loss: 0.7623434066772461] [G loss: [array(0.76315403, dtype=float32), array(0.76315403, dtype=float32), array(0.76315403, dtype=float32), array(0.16369048, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "63 [D loss: 0.7637311816215515] [G loss: [array(0.76454866, dtype=float32), array(0.76454866, dtype=float32), array(0.76454866, dtype=float32), array(0.16210938, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "64 [D loss: 0.7650310397148132] [G loss: [array(0.76577234, dtype=float32), array(0.76577234, dtype=float32), array(0.76577234, dtype=float32), array(0.15985577, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "65 [D loss: 0.7662606239318848] [G loss: [array(0.76700056, dtype=float32), array(0.76700056, dtype=float32), array(0.76700056, dtype=float32), array(0.15814394, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "66 [D loss: 0.7675316333770752] [G loss: [array(0.7682736, dtype=float32), array(0.7682736, dtype=float32), array(0.7682736, dtype=float32), array(0.1564832, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "67 [D loss: 0.7688371539115906] [G loss: [array(0.76965475, dtype=float32), array(0.76965475, dtype=float32), array(0.76965475, dtype=float32), array(0.15556066, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "68 [D loss: 0.7701824903488159] [G loss: [array(0.7710099, dtype=float32), array(0.7710099, dtype=float32), array(0.7710099, dtype=float32), array(0.15421195, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
      "69 [D loss: 0.7715038061141968] [G loss: [array(0.77229077, dtype=float32), array(0.77229077, dtype=float32), array(0.77229077, dtype=float32), array(0.15334821, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "70 [D loss: 0.7728253602981567] [G loss: [array(0.7736101, dtype=float32), array(0.7736101, dtype=float32), array(0.7736101, dtype=float32), array(0.15184858, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "71 [D loss: 0.7740547060966492] [G loss: [array(0.7748313, dtype=float32), array(0.7748313, dtype=float32), array(0.7748313, dtype=float32), array(0.15104167, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "72 [D loss: 0.7752554416656494] [G loss: [array(0.7759843, dtype=float32), array(0.7759843, dtype=float32), array(0.7759843, dtype=float32), array(0.14940068, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "73 [D loss: 0.776382565498352] [G loss: [array(0.777093, dtype=float32), array(0.777093, dtype=float32), array(0.777093, dtype=float32), array(0.14822635, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "74 [D loss: 0.7775405645370483] [G loss: [array(0.7783174, dtype=float32), array(0.7783174, dtype=float32), array(0.7783174, dtype=float32), array(0.1475, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "75 [D loss: 0.7788500785827637] [G loss: [array(0.7796494, dtype=float32), array(0.7796494, dtype=float32), array(0.7796494, dtype=float32), array(0.14597039, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "76 [D loss: 0.7802435755729675] [G loss: [array(0.7810706, dtype=float32), array(0.7810706, dtype=float32), array(0.7810706, dtype=float32), array(0.14448053, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
      "77 [D loss: 0.7814699411392212] [G loss: [array(0.782254, dtype=float32), array(0.782254, dtype=float32), array(0.782254, dtype=float32), array(0.14322917, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "78 [D loss: 0.7827455997467041] [G loss: [array(0.78354, dtype=float32), array(0.78354, dtype=float32), array(0.78354, dtype=float32), array(0.1420095, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "79 [D loss: 0.7839874625205994] [G loss: [array(0.78477246, dtype=float32), array(0.78477246, dtype=float32), array(0.78477246, dtype=float32), array(0.14101562, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "80 [D loss: 0.7852522730827332] [G loss: [array(0.78605074, dtype=float32), array(0.78605074, dtype=float32), array(0.78605074, dtype=float32), array(0.13985339, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "81 [D loss: 0.786522388458252] [G loss: [array(0.78735805, dtype=float32), array(0.78735805, dtype=float32), array(0.78735805, dtype=float32), array(0.13929115, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "82 [D loss: 0.7878299355506897] [G loss: [array(0.78864104, dtype=float32), array(0.78864104, dtype=float32), array(0.78864104, dtype=float32), array(0.13836597, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "83 [D loss: 0.7890931367874146] [G loss: [array(0.78986007, dtype=float32), array(0.78986007, dtype=float32), array(0.78986007, dtype=float32), array(0.13709077, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "84 [D loss: 0.7902657389640808] [G loss: [array(0.791021, dtype=float32), array(0.791021, dtype=float32), array(0.791021, dtype=float32), array(0.13639706, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "85 [D loss: 0.7913833856582642] [G loss: [array(0.79215276, dtype=float32), array(0.79215276, dtype=float32), array(0.79215276, dtype=float32), array(0.13571948, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "86 [D loss: 0.7925567626953125] [G loss: [array(0.7933411, dtype=float32), array(0.7933411, dtype=float32), array(0.7933411, dtype=float32), array(0.13487788, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "87 [D loss: 0.7937740087509155] [G loss: [array(0.79454386, dtype=float32), array(0.79454386, dtype=float32), array(0.79454386, dtype=float32), array(0.13458806, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "88 [D loss: 0.7950111031532288] [G loss: [array(0.7958515, dtype=float32), array(0.7958515, dtype=float32), array(0.7958515, dtype=float32), array(0.13395365, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "89 [D loss: 0.7962639331817627] [G loss: [array(0.79705596, dtype=float32), array(0.79705596, dtype=float32), array(0.79705596, dtype=float32), array(0.13368055, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "90 [D loss: 0.7974134683609009] [G loss: [array(0.7981738, dtype=float32), array(0.7981738, dtype=float32), array(0.7981738, dtype=float32), array(0.13255495, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "91 [D loss: 0.7986609935760498] [G loss: [array(0.7994526, dtype=float32), array(0.7994526, dtype=float32), array(0.7994526, dtype=float32), array(0.1314538, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "92 [D loss: 0.7998899221420288] [G loss: [array(0.8007049, dtype=float32), array(0.8007049, dtype=float32), array(0.8007049, dtype=float32), array(0.13071236, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "93 [D loss: 0.8011982440948486] [G loss: [array(0.8020081, dtype=float32), array(0.8020081, dtype=float32), array(0.8020081, dtype=float32), array(0.12982048, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "94 [D loss: 0.8024288415908813] [G loss: [array(0.8032287, dtype=float32), array(0.8032287, dtype=float32), array(0.8032287, dtype=float32), array(0.12927632, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "95 [D loss: 0.8037395477294922] [G loss: [array(0.80459356, dtype=float32), array(0.80459356, dtype=float32), array(0.80459356, dtype=float32), array(0.12858073, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "96 [D loss: 0.804969310760498] [G loss: [array(0.80576193, dtype=float32), array(0.80576193, dtype=float32), array(0.80576193, dtype=float32), array(0.12886597, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
      "97 [D loss: 0.8061720728874207] [G loss: [array(0.80695826, dtype=float32), array(0.80695826, dtype=float32), array(0.80695826, dtype=float32), array(0.12834822, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "98 [D loss: 0.8073786497116089] [G loss: [array(0.8081865, dtype=float32), array(0.8081865, dtype=float32), array(0.8081865, dtype=float32), array(0.12768309, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "99 [D loss: 0.8085949420928955] [G loss: [array(0.80939406, dtype=float32), array(0.80939406, dtype=float32), array(0.80939406, dtype=float32), array(0.1271875, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "100 [D loss: 0.8098070621490479] [G loss: [array(0.8106243, dtype=float32), array(0.8106243, dtype=float32), array(0.8106243, dtype=float32), array(0.12639232, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "101 [D loss: 0.8110362887382507] [G loss: [array(0.81182307, dtype=float32), array(0.81182307, dtype=float32), array(0.81182307, dtype=float32), array(0.12545955, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "102 [D loss: 0.8121716380119324] [G loss: [array(0.8129288, dtype=float32), array(0.8129288, dtype=float32), array(0.8129288, dtype=float32), array(0.1248483, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "103 [D loss: 0.8133094310760498] [G loss: [array(0.81410277, dtype=float32), array(0.81410277, dtype=float32), array(0.81410277, dtype=float32), array(0.12409855, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "104 [D loss: 0.8145653605461121] [G loss: [array(0.815383, dtype=float32), array(0.815383, dtype=float32), array(0.815383, dtype=float32), array(0.12366071, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
      "105 [D loss: 0.8157665729522705] [G loss: [array(0.8165513, dtype=float32), array(0.8165513, dtype=float32), array(0.8165513, dtype=float32), array(0.12323114, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "106 [D loss: 0.8169910907745361] [G loss: [array(0.8178385, dtype=float32), array(0.8178385, dtype=float32), array(0.8178385, dtype=float32), array(0.12266355, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "107 [D loss: 0.8182389736175537] [G loss: [array(0.81903386, dtype=float32), array(0.81903386, dtype=float32), array(0.81903386, dtype=float32), array(0.12181713, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "108 [D loss: 0.8194268941879272] [G loss: [array(0.820196, dtype=float32), array(0.820196, dtype=float32), array(0.820196, dtype=float32), array(0.12112959, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
      "109 [D loss: 0.8206092715263367] [G loss: [array(0.82140136, dtype=float32), array(0.82140136, dtype=float32), array(0.82140136, dtype=float32), array(0.12017045, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
      "110 [D loss: 0.8218684196472168] [G loss: [array(0.8227072, dtype=float32), array(0.8227072, dtype=float32), array(0.8227072, dtype=float32), array(0.1196509, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "111 [D loss: 0.8230886459350586] [G loss: [array(0.82388264, dtype=float32), array(0.82388264, dtype=float32), array(0.82388264, dtype=float32), array(0.11928014, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
      "112 [D loss: 0.8243021965026855] [G loss: [array(0.8251225, dtype=float32), array(0.8251225, dtype=float32), array(0.8251225, dtype=float32), array(0.11863938, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "113 [D loss: 0.8255157470703125] [G loss: [array(0.82633847, dtype=float32), array(0.82633847, dtype=float32), array(0.82633847, dtype=float32), array(0.11842106, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "114 [D loss: 0.8266998529434204] [G loss: [array(0.8274766, dtype=float32), array(0.8274766, dtype=float32), array(0.8274766, dtype=float32), array(0.11793479, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "115 [D loss: 0.8278976678848267] [G loss: [array(0.8287093, dtype=float32), array(0.8287093, dtype=float32), array(0.8287093, dtype=float32), array(0.1174569, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "116 [D loss: 0.8291323781013489] [G loss: [array(0.82997054, dtype=float32), array(0.82997054, dtype=float32), array(0.82997054, dtype=float32), array(0.11672009, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n",
      "117 [D loss: 0.8303276300430298] [G loss: [array(0.83113676, dtype=float32), array(0.83113676, dtype=float32), array(0.83113676, dtype=float32), array(0.1162606, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "118 [D loss: 0.8315560817718506] [G loss: [array(0.83238053, dtype=float32), array(0.83238053, dtype=float32), array(0.83238053, dtype=float32), array(0.11567752, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "119 [D loss: 0.8327465057373047] [G loss: [array(0.83352375, dtype=float32), array(0.83352375, dtype=float32), array(0.83352375, dtype=float32), array(0.11523438, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "120 [D loss: 0.8338976502418518] [G loss: [array(0.8346801, dtype=float32), array(0.8346801, dtype=float32), array(0.8346801, dtype=float32), array(0.11492769, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "121 [D loss: 0.8351207971572876] [G loss: [array(0.83593416, dtype=float32), array(0.83593416, dtype=float32), array(0.83593416, dtype=float32), array(0.1142418, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
      "122 [D loss: 0.8363061547279358] [G loss: [array(0.8370756, dtype=float32), array(0.8370756, dtype=float32), array(0.8370756, dtype=float32), array(0.11356708, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "123 [D loss: 0.8374796509742737] [G loss: [array(0.8382885, dtype=float32), array(0.8382885, dtype=float32), array(0.8382885, dtype=float32), array(0.11315524, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
      "124 [D loss: 0.838657557964325] [G loss: [array(0.83946526, dtype=float32), array(0.83946526, dtype=float32), array(0.83946526, dtype=float32), array(0.113, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step\n",
      "125 [D loss: 0.8398456573486328] [G loss: [array(0.84062463, dtype=float32), array(0.84062463, dtype=float32), array(0.84062463, dtype=float32), array(0.11272322, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "126 [D loss: 0.8410176038742065] [G loss: [array(0.8418329, dtype=float32), array(0.8418329, dtype=float32), array(0.8418329, dtype=float32), array(0.11208169, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
      "127 [D loss: 0.8421584367752075] [G loss: [array(0.84295195, dtype=float32), array(0.84295195, dtype=float32), array(0.84295195, dtype=float32), array(0.11206055, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
      "128 [D loss: 0.843360185623169] [G loss: [array(0.84418845, dtype=float32), array(0.84418845, dtype=float32), array(0.84418845, dtype=float32), array(0.11167636, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "129 [D loss: 0.8445398807525635] [G loss: [array(0.8453578, dtype=float32), array(0.8453578, dtype=float32), array(0.8453578, dtype=float32), array(0.11153846, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
      "130 [D loss: 0.8457613587379456] [G loss: [array(0.8465771, dtype=float32), array(0.8465771, dtype=float32), array(0.8465771, dtype=float32), array(0.11116412, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
      "131 [D loss: 0.8469523191452026] [G loss: [array(0.8477284, dtype=float32), array(0.8477284, dtype=float32), array(0.8477284, dtype=float32), array(0.11044034, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step\n",
      "132 [D loss: 0.8480896353721619] [G loss: [array(0.848896, dtype=float32), array(0.848896, dtype=float32), array(0.848896, dtype=float32), array(0.11019737, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "133 [D loss: 0.849197268486023] [G loss: [array(0.84995914, dtype=float32), array(0.84995914, dtype=float32), array(0.84995914, dtype=float32), array(0.10995802, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "134 [D loss: 0.8503379821777344] [G loss: [array(0.851161, dtype=float32), array(0.851161, dtype=float32), array(0.851161, dtype=float32), array(0.10960648, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "135 [D loss: 0.85151207447052] [G loss: [array(0.85228646, dtype=float32), array(0.85228646, dtype=float32), array(0.85228646, dtype=float32), array(0.10926011, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "136 [D loss: 0.8526297807693481] [G loss: [array(0.8534226, dtype=float32), array(0.8534226, dtype=float32), array(0.8534226, dtype=float32), array(0.10891879, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
      "137 [D loss: 0.853735089302063] [G loss: [array(0.85450804, dtype=float32), array(0.85450804, dtype=float32), array(0.85450804, dtype=float32), array(0.10858243, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "138 [D loss: 0.8548274040222168] [G loss: [array(0.85558593, dtype=float32), array(0.85558593, dtype=float32), array(0.85558593, dtype=float32), array(0.1082509, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "139 [D loss: 0.8558859825134277] [G loss: [array(0.85664654, dtype=float32), array(0.85664654, dtype=float32), array(0.85664654, dtype=float32), array(0.1078125, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "140 [D loss: 0.85695481300354] [G loss: [array(0.8577377, dtype=float32), array(0.8577377, dtype=float32), array(0.8577377, dtype=float32), array(0.1079344, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "141 [D loss: 0.8581466674804688] [G loss: [array(0.8589821, dtype=float32), array(0.8589821, dtype=float32), array(0.8589821, dtype=float32), array(0.10739437, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "142 [D loss: 0.8592582941055298] [G loss: [array(0.86002016, dtype=float32), array(0.86002016, dtype=float32), array(0.86002016, dtype=float32), array(0.10708042, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
      "143 [D loss: 0.8603845834732056] [G loss: [array(0.86118335, dtype=float32), array(0.86118335, dtype=float32), array(0.86118335, dtype=float32), array(0.10666233, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "144 [D loss: 0.8615008592605591] [G loss: [array(0.8622656, dtype=float32), array(0.8622656, dtype=float32), array(0.8622656, dtype=float32), array(0.10614224, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
      "145 [D loss: 0.8626502752304077] [G loss: [array(0.8634722, dtype=float32), array(0.8634722, dtype=float32), array(0.8634722, dtype=float32), array(0.10562928, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "146 [D loss: 0.8638768196105957] [G loss: [array(0.86465466, dtype=float32), array(0.86465466, dtype=float32), array(0.86465466, dtype=float32), array(0.1051233, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "147 [D loss: 0.8650317192077637] [G loss: [array(0.86583155, dtype=float32), array(0.86583155, dtype=float32), array(0.86583155, dtype=float32), array(0.10472973, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "148 [D loss: 0.866182804107666] [G loss: [array(0.86697, dtype=float32), array(0.86697, dtype=float32), array(0.86697, dtype=float32), array(0.10423658, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "149 [D loss: 0.8672977685928345] [G loss: [array(0.86809593, dtype=float32), array(0.86809593, dtype=float32), array(0.86809593, dtype=float32), array(0.10385416, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "150 [D loss: 0.8685292601585388] [G loss: [array(0.8693615, dtype=float32), array(0.8693615, dtype=float32), array(0.8693615, dtype=float32), array(0.10337334, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "151 [D loss: 0.869713544845581] [G loss: [array(0.87050325, dtype=float32), array(0.87050325, dtype=float32), array(0.87050325, dtype=float32), array(0.10289885, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "152 [D loss: 0.8708616495132446] [G loss: [array(0.87164044, dtype=float32), array(0.87164044, dtype=float32), array(0.87164044, dtype=float32), array(0.10232843, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "153 [D loss: 0.8719483613967896] [G loss: [array(0.8727166, dtype=float32), array(0.8727166, dtype=float32), array(0.8727166, dtype=float32), array(0.10217126, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
      "154 [D loss: 0.8729715943336487] [G loss: [array(0.87369907, dtype=float32), array(0.87369907, dtype=float32), array(0.87369907, dtype=float32), array(0.10171371, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "155 [D loss: 0.8740224838256836] [G loss: [array(0.8747897, dtype=float32), array(0.8747897, dtype=float32), array(0.8747897, dtype=float32), array(0.10166266, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "156 [D loss: 0.8750810623168945] [G loss: [array(0.8758298, dtype=float32), array(0.8758298, dtype=float32), array(0.8758298, dtype=float32), array(0.1013137, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "157 [D loss: 0.8761355876922607] [G loss: [array(0.8769053, dtype=float32), array(0.8769053, dtype=float32), array(0.8769053, dtype=float32), array(0.10106803, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "158 [D loss: 0.877263069152832] [G loss: [array(0.87808365, dtype=float32), array(0.87808365, dtype=float32), array(0.87808365, dtype=float32), array(0.10082547, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "159 [D loss: 0.878369927406311] [G loss: [array(0.8791296, dtype=float32), array(0.8791296, dtype=float32), array(0.8791296, dtype=float32), array(0.10029297, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "160 [D loss: 0.8794754147529602] [G loss: [array(0.8802588, dtype=float32), array(0.8802588, dtype=float32), array(0.8802588, dtype=float32), array(0.09976708, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "161 [D loss: 0.8805575370788574] [G loss: [array(0.881293, dtype=float32), array(0.881293, dtype=float32), array(0.881293, dtype=float32), array(0.09953704, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "162 [D loss: 0.8816167116165161] [G loss: [array(0.8823797, dtype=float32), array(0.8823797, dtype=float32), array(0.8823797, dtype=float32), array(0.09902224, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "163 [D loss: 0.8827423453330994] [G loss: [array(0.8835348, dtype=float32), array(0.8835348, dtype=float32), array(0.8835348, dtype=float32), array(0.09870427, dtype=float32)]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, latent_dim, **kwargs):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.generator = self.build_generator()\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        img = self.generator(inputs)\n",
    "        return img\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        x = Dense(128 * 16 * 16, activation=\"relu\")(noise)\n",
    "        x = Reshape((16, 16, 128))(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = UpSampling2D()(x)\n",
    "        x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(3, kernel_size=3, padding=\"same\")(x)\n",
    "        outputs = Activation(\"tanh\")(x)\n",
    "        return Model(noise, outputs)\n",
    "\n",
    "# データの読み込み\n",
    "def load_data(dataset_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        img = Image.open(os.path.join(dataset_path, filename)).convert('RGB')  # ここでRGBに変換\n",
    "        img = img.resize((64, 64))\n",
    "        img = np.array(img)\n",
    "        img = (img / 127.5) - 1.0\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "# データセットのパスを指定\n",
    "dataset_path = r\"C:\\Users\\user\\Downloads\\sample-cards-data\\images\\images\"\n",
    "X_train = load_data(dataset_path)\n",
    "\n",
    "# GANのパラメータ設定\n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "channels = 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "\n",
    "def build_generator(latent_dim, img_shape):\n",
    "    inputs = Input(shape=(latent_dim,))\n",
    "    x = MyLayer(latent_dim)(inputs)\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "# 識別器の構築\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "# GANの構築\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    fake_img = generator(gan_input)\n",
    "    gan_output = discriminator(fake_img)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return gan\n",
    "\n",
    "# 訓練用関数\n",
    "def train_gan(generator, discriminator, gan, X_train, epochs, batch_size=32, save_interval=10):\n",
    "    valid = np.ones((batch_size, 1), dtype=np.float32)\n",
    "    fake = np.zeros((batch_size, 1), dtype=np.float32)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        g_loss = gan.train_on_batch(noise, valid)\n",
    "\n",
    "        # 進捗の表示\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
    "\n",
    "        # 一定間隔で生成画像を保存\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(generator, epoch)\n",
    "\n",
    "# 生成した画像を保存する関数\n",
    "def save_imgs(generator, epoch, r=5, c=5):\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # 生成した画像を0から1の範囲に変換\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt])\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# パラメータ設定\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "save_interval = 50\n",
    "\n",
    "# モデルの構築と訓練\n",
    "generator = build_generator(latent_dim, img_shape)\n",
    "discriminator = build_discriminator(img_shape)\n",
    "\n",
    "discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "generator.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "train_gan(generator, discriminator, gan, X_train, epochs=epochs, batch_size=batch_size, save_interval=save_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d75783-4b5c-4a2c-9ebe-15c40af4449f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
